{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Preparing Data ---",
      "\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Loading and Preparation ---",
    "print('--- 1. Loading and Preparing Data ---')",
    "try:",
    "    proteomics_df = pd.read_csv('BRCA_proteomics_gene_abundance_log2_reference_intensity_normalized_Tumor.txt', sep='\t', index_col=0)",
    "    meta_df = pd.read_csv('BRCA_meta.txt', sep='\t', index_col=0)",
    "    phenotype_df = pd.read_csv('BRCA_phenotype.txt', sep='\t', index_col=0)",
    "    survival_df = pd.read_csv('BRCA_survival.txt', sep='\t', index_col=0)",
    "except FileNotFoundError as e:",
    "    print(f'Error: {e}')",
    "    exit()",
    "proteomics_df = proteomics_df.T",
    "nan_ratio = proteomics_df.isna().mean()",
    "proteomics_df = proteomics_df.loc[:, nan_ratio <= 0.3]",
    "proteomics_df = proteomics_df.fillna(proteomics_df.mean())",
    "df = pd.concat([meta_df, phenotype_df, survival_df, proteomics_df], axis=1, join='inner')",
    "df_clean = df.dropna(subset=['Stage'])",
    "",
    "# Define features and target",
    "X = df_clean[proteomics_df.columns]",
    "y = df_clean['Stage']",
    "",
    "# Split data",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)",
    "",
    "# Scale features",
    "scaler = StandardScaler()",
    "X_train_scaled = scaler.fit_transform(X_train)",
    "X_val_scaled = scaler.transform(X_val)",
    "X_test_scaled = scaler.transform(X_test)",
    "",
    "print('Data preparation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2a. Baseline: Logistic Regression ---",
      "\n",
      "Macro F1: 0.3477\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Experimentation ---",
    "results = {}",
    "",
    "# Experiment 1: Baseline Logistic Regression",
    "print('\n--- 2a. Baseline: Logistic Regression ---')",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000, multi_class='ovr')",
    "log_reg.fit(X_train_scaled, y_train)",
    "y_pred_lr = log_reg.predict(X_val_scaled)",
    "results['Logistic Regression'] = f1_score(y_val, y_pred_lr, average='macro', zero_division=0)",
    "print(f"Macro F1: {results['Logistic Regression']:.4f}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2b. Random Forest (Original Data) ---",
      "\n",
      "Macro F1: 0.3091\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Random Forest on Original Data",
    "print('\n--- 2b. Random Forest (Original Data) ---')",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)",
    "rf.fit(X_train_scaled, y_train)",
    "y_pred_rf = rf.predict(X_val_scaled)",
    "results['Random Forest'] = f1_score(y_val, y_pred_rf, average='macro', zero_division=0)",
    "print(f"Macro F1: {results['Random Forest']:.4f}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Applying SMOTE for Class Imbalance ---",
      "\n",
      "Original training shape: (65, 9242)",
      "SMOTE resampled training shape: (129, 9242)",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Applying SMOTE for Class Imbalance",
    "print('\n--- 3. Applying SMOTE for Class Imbalance ---')",
    "smallest_class_size = y_train.value_counts().min()",
    "k = smallest_class_size - 1 if smallest_class_size > 1 else 1",
    "smote = SMOTE(random_state=42, k_neighbors=k)",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)",
    "print(f"Original training shape: {X_train_scaled.shape}")",
    "print(f"SMOTE resampled training shape: {X_train_smote.shape}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4a. Random Forest with SMOTE ---",
      "\n",
      "Macro F1: 0.3960\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4a: Random Forest with SMOTE",
    "print('\n--- 4a. Random Forest with SMOTE ---')",
    "rf_smote = RandomForestClassifier(random_state=42, n_estimators=100)",
    "rf_smote.fit(X_train_smote, y_train_smote)",
    "y_pred_rf_smote = rf_smote.predict(X_val_scaled)",
    "results['Random Forest + SMOTE'] = f1_score(y_val, y_pred_rf_smote, average='macro', zero_division=0)",
    "print(f"Macro F1: {results['Random Forest + SMOTE']:.4f}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4b. XGBoost with SMOTE ---",
      "\n",
      "Macro F1: 0.3248\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4b: XGBoost with SMOTE",
    "print('\n--- 4b. XGBoost with SMOTE ---')",
    "le = LabelEncoder()",
    "y_train_smote_encoded = le.fit_transform(y_train_smote)",
    "y_val_encoded = le.transform(y_val)",
    "y_test_encoded = le.transform(y_test)",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')",
    "xgb_model.fit(X_train_smote, y_train_smote_encoded)",
    "y_pred_xgb_encoded = xgb_model.predict(X_val_scaled)",
    "y_pred_xgb = le.inverse_transform(y_pred_xgb_encoded)",
    "results['XGBoost + SMOTE'] = f1_score(y_val, y_pred_xgb, average='macro', zero_division=0)",
    "print(f"Macro F1: {results['XGBoost + SMOTE']:.4f}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Hyperparameter Tuning for Random Forest (with SMOTE) ---",
      "\n",
      "Best parameters found: {'max_depth': 10, 'min_samples_leaf': 4, 'n_estimators': 200}",
      "Macro F1: 0.2222\n"
     ]
    }
   ],
   "source": [
    "# Experiment 5: Hyperparameter Tuning with GridSearchCV",
    "print('\n--- 5. Hyperparameter Tuning for Random Forest (with SMOTE) ---')",
    "param_grid = {",
    "    'n_estimators': [100, 200],",
    "    'max_depth': [10, 20, None],",
    "    'min_samples_leaf': [1, 2, 4]",
    "}",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=0, scoring='f1_macro')",
    "grid_search.fit(X_train_smote, y_train_smote)",
    "print(f"Best parameters found: {grid_search.best_params_}")",
    "best_rf = grid_search.best_estimator_",
    "y_pred_best_rf = best_rf.predict(X_val_scaled)",
    "results['Tuned RF + SMOTE'] = f1_score(y_val, y_pred_best_rf, average='macro', zero_division=0)",
    "print(f"Macro F1: {results['Tuned RF + SMOTE']:.4f}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 6. Final Evaluation on Test Set ---",
      "\n",
      "Validation Performance Summary (Macro F1-Score):",
      "Random Forest + SMOTE: 0.3960",
      "Logistic Regression: 0.3477",
      "XGBoost + SMOTE: 0.3248",
      "Random Forest: 0.3091",
      "Tuned RF + SMOTE: 0.2222",
      "\n",
      "Best performing model on validation set: Random Forest + SMOTE",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Final Evaluation ---",
    "print('\n--- 6. Final Evaluation on Test Set ---')",
    "print('\nValidation Performance Summary (Macro F1-Score):')",
    "sorted_results = sorted(results.items(), key=lambda item: item[1], reverse=True)",
    "for model, score in sorted_results:",
    "    print(f"{model}: {score:.4f}")",
    "",
    "best_model_name = sorted_results[0][0]",
    "print(f"\nBest performing model on validation set: {best_model_name}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Report for Best Model (Random Forest + SMOTE) on Test Set ---",
      "              precision    recall  f1-score   support",
      "",
      "     Stage I       0.00      0.00      0.00         1",
      "    Stage II       0.70      0.93      0.80        15",
      "   Stage III       0.50      0.17      0.25         6",
      "",
      "    accuracy                           0.68        22",
      "   macro avg       0.40      0.37      0.35        22",
      "weighted avg       0.61      0.68      0.61        22",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the best model object for final prediction",
    "if best_model_name == 'Tuned RF + SMOTE':",
    "    final_model = best_rf",
    "elif best_model_name == 'Random Forest + SMOTE':",
    "    final_model = rf_smote",
    "elif best_model_name == 'XGBoost + SMOTE':",
    "    final_model = xgb_model",
    "elif best_model_name == 'Logistic Regression':",
    "    final_model = log_reg",
    "else:",
    "    final_model = rf",
    "",
    "y_pred_final = final_model.predict(X_test_scaled)",
    "if best_model_name == 'XGBoost + SMOTE':",
    "    y_pred_final = le.inverse_transform(y_pred_final)",
    "",
    "print(f'\n--- Final Report for Best Model ({best_model_name}) on Test Set ---')",
    "print(classification_report(y_test, y_pred_final, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}